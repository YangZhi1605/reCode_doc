# 关于模型训练记录的存档

## 有监督学习方向的训练

### 一、KNN算法预测尝试 （很费时间）





#### 第一次训练tag



**样本数据量：**

![1693661317648](E:\文档_Typora\关于模型训练记录的存档.assets\1693661317648.png)

**模型构建指标**



```python
param_dict = {"n_neighbors": [3, 5, 7, 9]} # 取的邻居k的数据量
cv_n = 3 # 交叉验证的次数
estimator = GridSearchCV(estimator,param_grid=param_dict,cv=cv_n)
```

**模型运行时间：**

21:02——0:19 —— `这个模型得调整，跑了这么久都没有出结果。`





#### 第二次训练tag



**数据量：**30w （）

**模型指标：**



```python
param_dict = {"n_neighbors": [3, 5, 7, 9]} # 取的邻居k的数据量
cv_n = 3 # 交叉验证的次数
estimator = GridSearchCV(estimator,param_grid=param_dict,cv=cv_n)
```



**模型运行时间：**

15:48-15:56 

 **模型效果**：

![1693728031296](E:\文档_Typora\关于模型训练记录的存档.assets\1693728031296.png)



**问题反思：**

训练数据量过小



#### 第三次训练



**训练数据量**：

50W

**训练时间**：

16:05 —— 16:21 

**训练效果：**

![1693728475056](E:\文档_Typora\关于模型训练记录的存档.assets\1693728475056.png)

**训练效果反思：**

数据量浮动不大，调整网格搜索和交叉验证



#### 第四次训练记录

**全数据量再测试：**



**训练时间：**

16:24 —— 22:31 `约跑了6个小时`

这个跑的够长。。。



**模型评估效果：**

![1693751550553](E:\文档_Typora\关于模型训练记录的存档.assets\1693751550553.png)



`暂时可以用它了`。

![1693813565904](E:\文档_Typora\关于模型训练记录的存档.assets\1693813565904.png)

其交叉验证和搜索出的结果，可以为后续的再优化缩小范围了







**训练反思：**

—— **这个得明天训练看看了**

根据sklearn的官方文档介绍，纵使网格搜索和随机搜索提供同样的参数指标，但是随机搜索会更快

![1693731684030](E:\文档_Typora\关于模型训练记录的存档.assets\1693731684030.png)

待会优化为随机搜索确定超参数



**重新明确KNN的参数是这种的:**



```python 
estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                            metric='minkowski',
                                            metric_params=None, 											n_jobs=None,
                                            n_neighbors=5, p=2,
                                            weights='uniform'),
             iid='deprecated', n_jobs=None,
             param_grid={'n_neighbors': [3, 5, 7, 9]}, 						pre_dispatch='2*n_jobs',
             refit=True, return_train_score=False, scoring=None, 				verbose=0). Check the list of available parameters with 			`estimator.get_params().keys()`.
```

**重新明确超参数**

>超参数是机器学习模型训练过程中的设置项，它们不是由模型自动学习的，而是在训练之前手动设置的参数。超参数的选择可以影响模型的性能和训练速度，因此调整超参数是模型优化的一部分。
>
>在随机搜索中，需要指定要调整的超参数及其分布。这些超参数的名称通常与你选择的机器学习算法有关，不同的算法有不同的超参数。以下是一些常见的机器学习算法以及它们可能涉及的一些超参数：

**关于随机搜索进行超参数估计**

**param_distributions**（参数分布）：一个字典，其中包含要进行随机搜索的超参数及其分布。这个字典的键是超参数的名称，而值是用于指定参数分布的对象 





#### 第五次训练

>**尝试通过随机搜索处理超参数的效率：**

**模型训练时间：**15:20- 18：02  `3个小时`

**训练结果：**蓝屏未知

**训练反思：**超参数的配比不对以及整个模型处理全数据乏力







#### 六次训练

>**比对随机搜索和网格搜索确定超参数效率**

模型运行时间：10:50——12:51   `2个小时`

———— **时间确实是直接省了1/3**

—————— 以后假如需要通过搜索确定超参数会快很多了。

模型运行效果：

模型运行超参数范围确定:裁剪运行搜索的次数为3。比对网格搜索



```python
param_dict = {"n_neighbors": [ 4, 5, 7, 8]}
cv_n = 3
# estimator = GridSearchCV(estimator,param_grid=param_dict,cv=cv_n)

# 运行随机搜索
n_iter_search = 3
estimator_randomCV = RandomizedSearchCV(estimator_random_test,param_distributions=param_dict,n_iter=n_iter_search)
```



### 二、随机森林算法的预测尝试（超参数调报废）



#### 第一次训练

训练时间：16:45 —— 21:10 `5个小时`

训练数据量和参数：全数据量 + 参数



```python
# 这里确认的超参数，目前搜森林里树的数量和树的最大深度
param_dict = {"n_estimators": [120,200,300,500,800,1200], "max_depth": [5,8,15,25,30]}
n_iter_search = 3
estimator_random = RandomizedSearchCV(estimator_random,param_distributions=param_dict,n_iter=n_iter_search)
```



**预测效果如下——更有进步了**：

![1694005604080](E:\文档_Typora\关于模型训练记录的存档.assets\1694005604080.png)





**反思，整体的时间量也缩减了。效果更好一些**

但是太大了。2.5个G的模型







#### 第二次训练

训练时间：11:20 —— 13:30 `3个小时`

训练数据量：全数据

训练参数：



```python
# 矫正模型的超参数 —— 根据上一个模型的预测效果，再次调整随机森林的预测效果
# 这里确认的超参数，目前搜森林里树的数量和树的最大深度
param_dict = {"n_estimators": [290,300,320,340,350], "max_depth": [28,30,32,35,36]}
n_iter_search = 3 #交叉验证的层数还是定为三层
estimator_random_para = RandomizedSearchCV(estimator_random_para,param_distributions=param_dict,n_iter=n_iter_search)
```



训练效果：

![1694066539833](E:\文档_Typora\关于模型训练记录的存档.assets\1694066539833.png)

训练反思：

**很快，但是这个模型练报废了。这个准确率为什么这么低。**

**重复确认，确实是训报废了：**

![1694068647175](E:\文档_Typora\关于模型训练记录的存档.assets\1694068647175.png)



> `关于分类问题的模型评估方法三：`
>



分类报告提供了关于模型性能的详细信息，包括精确度（Precision）、召回率（Recall）、F1分数（F1-Score）等指标。要判断模型的好坏，可以根据以下几个指标来解释分类报告的结果：

`TP = True Possitive`

`FN = False Negative`

重心看F1-Score吧

![1694070339224](E:\文档_Typora\关于模型训练记录的存档.assets\1694070339224.png)

![1694070381846](E:\文档_Typora\关于模型训练记录的存档.assets\1694070381846.png)





#### 第三次训练

重新拍定超参数，再次训练

数据已经处理得比较干净和标注了。那只能是超参数的问题了



```python
# 矫正模型的超参数 —— 根据上一个模型的预测十分差的效果，再次调整随机森林的预测效果
# 这里确认的超参数，目前搜森林里树的数量和树的最大深度
param_dict = {"n_estimators": [320,380,420,500,600], "max_depth": [15,20,30,35,40]}
n_iter_search = 3 #交叉验证的层数还是定为三层
estimator_random_2023_97_2 = RandomizedSearchCV(estimator_random_2023_97_2,param_distributions=param_dict,n_iter=n_iter_search)
```



训练时间：14:55 —— 17:55：`3个小时`

训练效果：差

![1694088305934](E:\文档_Typora\关于模型训练记录的存档.assets\1694088305934.png)





#### 第四次训练

>**前期铺垫：**

学一个绘制学习曲线定数据范围。

对随机森林调参
https://zhuanlan.zhihu.com/p/126288078

sklearn.model_selection.cross_val_score —— 每次交叉验证运行时估算器得分的数组。 
https://scikit-learn.org.cn/view/663.html



训练时间：8:45 —— 10:52 `2个小时`

训练数据量：全数据集

训练参数：

` RandomForestClassifier(n_estimators=300, random_state=75)`



训练效果：![1694141570903](E:\文档_Typora\关于模型训练记录的存档.assets\1694141570903.png)



#### 第五次训练

训练开始时间11:00 —— 23：58 `11个小时`

训练数据量：全数据集



训练参数：



```python
# 调参，绘制学习曲线来调参n_estimators（对随机森林影响最大）
score_lt = []

# 每隔10步建立一个随机森林，获得不同n_estimators的得分
for i in range(220,430,10):
    rfc = RandomForestClassifier(n_estimators=i+1
                                ,random_state=75)
    score = cross_val_score(rfc, x,y, cv=10).mean()
    score_lt.append(score)
score_max = max(score_lt)
print('最大得分：{}'.format(score_max),
      '子树数量为：{}'.format(score_lt.index(score_max)*10+1))

# 绘制学习曲线
x = np.arange(1,201,10)
plt.subplot(111)
plt.plot(x, score_lt, 'r-')
plt.show()
```



训练指标效果：

>**未得到效果**



#### 第六次训练

训练开始时间7:00 —— 00:34 `17个小时`

训练数据量：全数据集

训练的参数放置：



```python

# 调参，绘制学习曲线来调参n_estimators（对随机森林影响最大）
score_lt = []

# 每隔10步建立一个随机森林，获得不同n_estimators的得分
for i in range(260,420,10):
    rfc = RandomForestClassifier(n_estimators=i+1
                                ,random_state=75)
    score = cross_val_score(rfc, x,y, cv=5).mean()
    score_lt.append(score)
score_max = max(score_lt)
print('最大得分：{}'.format(score_max),
      '子树数量为：{}'.format(score_lt.index(score_max)*10+1))

# 绘制学习曲线
x = np.arange(10,450,10)
plt.subplot(111)
plt.plot(x, score_lt, 'r-')
plt.show()
```



训练效果：

>**未得到效果**



>**反思：**

目前确定为每个超参数的校验是约三个小时。我这里是步进了16个超参数，严格来说，应该是需要约40个小时才能够得到衡估曲线。因为学校会停电，这部分的训练暂停。







#### 第七次训练

>**本次训练主要是为了使用随机森林这种集成算法，且对特征值的波动不敏感的算法来对设备的工作时长进行预测。**

训练数据量：全数据量

训练参数：



```python
# 这里确认的超参数，目前搜森林里树的数量和树的最大深度
param_dict = {
    "n_estimators": [120, 200, 300, 500, 750, 800, 1000, 1200],
    "max_depth": [5, 8, 15, 25, 30, 60],
    "min_samples_leaf": [1, 2, 3, 4, 5, 6, 7]  # 选择一个整数值
}
n_iter_search = 3
estimator_random = RandomizedSearchCV(rf_regressor,param_distributions=param_dict,n_iter=n_iter_search)
```





训练时间：10:10 ——  `没有训练完，停电了`

训练效果：

`求一个好一点的效果吧，30%的精确率真的伤不起`

大概率今天又训练不完咯，要断电啦



训练反思：

明天砍超参数，然后继续训练





#### 第八次训练

训练数据量：全数据量

训练参数：



```python
# 这里确认的超参数，目前搜森林里树的数量和树的最大深度
param_dict = {
    "n_estimators": [120, 200, 300, 500],
    "max_depth": [ 25, 30, 60],
    "min_samples_leaf": [1, 2, 3,]  # 选择一个整数值
}
n_iter_search = 3
estimator_random = RandomizedSearchCV(rf_regressor,param_distributions=param_dict,n_iter=n_iter_search)
```

训练开始时间：8:50 —— 20:03 `12个小时`

`太感人了，终于跑出结果了....`



训练效果：

![1694684197853](E:\文档_Typora\关于模型训练记录的存档.assets\1694684197853.png)



训练反思：

对比之前的30%好太多了。3个G，也是够大了。。。

![1694684410605](E:\文档_Typora\关于模型训练记录的存档.assets\1694684410605.png)

对比岭回归还是有进步，考虑调优。







### 三、逻辑回归算法的预测尝试

#### 我对算法的认识





#### 第一次训练

训练时间：8:40 —— 9：40

训练数据量：全数据量

训练效果：

![1694395557464](E:\文档_Typora\关于模型训练记录的存档.assets\1694395557464.png)



>**从召回率来看：危险和警报的召回率比较高，这里不错。**
>
>**从f1-socre判断稳健性来看：正常的模型稳健性待定。**
>
>**综合的精确性、宏平均 (macro avg) 的精确度、加权平均 (weighted avg) 的精确度等综合评估还是不错的**



训练反思：

>**后续考虑怎么处理正常的预测问题，以及如何将模型的精度再提高的问题**





#### 第二次训练

训练数据量：全数据量

训练时间：10:05 —— 11:20 `一个半小时`

训练参数:



```python
parameters = {'penalty':['l1','l2'],
             'C':np.linspace(0.05,1,19)}
clf = clf.fit(x_train,y_train)
GScv = GridSearchCV(clf, parameters, cv=10)
GScv.fit(x_train,y_train)
print("时间:{}".format(datetime.datetime.fromtimestamp(time()-current_time).strftime("%M:%S:%f")))
```



训练效果：

![1694492521187](E:\文档_Typora\关于模型训练记录的存档.assets\1694492521187.png)



训练反思：

**不知道为什么，很难突破到90以上**



#### 第三次训练

数据量：全数据量

训练时间：12:25 —— 14:38 `3个小时`

训练参数：



```python
penaltys = ['l1' , 'l2']
Cs = np.linspace(0.5,90,115)
parameters = dict(penalty = penaltys , C = Cs)

GScv = GridSearchCV(clf, parameters, cv=10)
GScv.fit(x_train,y_train)
```





训练效果：

![1694500638666](E:\文档_Typora\关于模型训练记录的存档.assets\1694500638666.png)



训练反思：最后上升的效果十分单薄，准备做最后一次超参数训练调整



#### 第四次训练

训练数据量：全数据量

训练时间：14:45 —— 17:08 `3个小时`

训练参数：



````python
penaltys = ['l1' , 'l2']
Cs = np.linspace(16,116,110) #划分从16开始，到116的110个超参数
parameters = dict(penalty = penaltys , C = Cs)

GScv = GridSearchCV(clf, parameters, cv=10) 
GScv.fit(x_train,y_train)
# 输出最佳结果和最佳参数
# 如果最佳值在候选参数的边缘，最好再尝试更大或更小的参数，直到找到拐点
print(GScv.best_score_)
print(GScv.best_params_)
````



训练锁定的超参数如下：

![1694509748839](E:\文档_Typora\关于模型训练记录的存档.assets\1694509748839.png)

![1694509865088](E:\文档_Typora\关于模型训练记录的存档.assets\1694509865088.png)

`也就是这种16的正则强度下的效果应该是相对最好的了`

![1694510169832](E:\文档_Typora\关于模型训练记录的存档.assets\1694510169832.png)





>**于逻辑回归而言，我现在需要处理`安全`的精确率、召回率**





#### 第五次训练

>**本次训练，我想使用逻辑回归对设备可工作时长进行一下预测。**

训练数据量：全数据量

训练参数：为调整超参数

训练时间：

训练效果：

训练反思：逻辑回归是严格处理分类问题的，我这里被判定为连续型的`（continuous）`。因此此法不通







### 随机梯度下降算法预测训练（存在问题）

训练数据量：全数据量

训练时间14:55 —— 15:30

训练参数：



```python
sgdClf = SGDClassifier(eta0=0.01, max_iter=10000)
```



训练效果：

![1694503455509](E:\文档_Typora\关于模型训练记录的存档.assets\1694503455509.png)

**可谓相当的差**



训练反思：

我再读读API吧，



>**随机梯度下降目前是一筹莫展，预测的效果太低太低了。不知道如何拔高预测率**







### 四、岭回归算法训练测试 （存在问题）

>**解决设备可工作时长的预测**



#### 第一次训练

训练数据量：全数据量

训练时长：15:30 —— 15:55

训练参数：



```python

estimator = Ridge(alpha=0.5, max_iter=10000)
estimator.fit(x_train, y_train)

```





训练效果：
![1694503919960](E:\文档_Typora\关于模型训练记录的存档.assets\1694503919960.png)

这个模型其实也是很低







#### 第二次训练

训练数据量：全数据量

训练时间：16:03 —— 16:15

训练参数调整：

![1694505601361](E:\文档_Typora\关于模型训练记录的存档.assets\1694505601361.png)



训练效果：

![1694505776565](E:\文档_Typora\关于模型训练记录的存档.assets\1694505776565.png)





训练反思：计划对目标值进行标准化处理。模型评分太低了，不应该这种的



#### 第三次训练



训练数据量：全数据量

训练时间：16:22 —— 16：30



训练参数：

![1694507452617](E:\文档_Typora\关于模型训练记录的存档.assets\1694507452617.png)



训练效果：

![1694507465822](E:\文档_Typora\关于模型训练记录的存档.assets\1694507465822.png)

**对目标值进行标准化之后，训练的效果仍然不佳**

`但是均方误差`很小很小了。

但是从散点图和残差图指标的衡估而言：很差

![1694508360676](E:\文档_Typora\关于模型训练记录的存档.assets\1694508360676.png)



![1694508395115](E:\文档_Typora\关于模型训练记录的存档.assets\1694508395115.png)





>**岭回归也是效果很差。数据的问题吗？**













